{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CS 3780/5780 Creative Project: </h2>\n",
    "<h3>Emotion Classification of Natural Language</h3>\n",
    "\n",
    "Names and NetIDs for your group members: Alexia Adams (aa862),\n",
    "Matthew Mentis-Cort (mam692)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introduction:</h3>\n",
    "\n",
    "<p> The creative project is about conducting a real-world machine learning project on your own, with everything that is involved. Unlike in the programming projects 1-5, where we gave you all the scaffolding and you just filled in the blanks, you now start from scratch. The past programming projects provide templates for how to do this (and you can reuse part of your code if you wish), and the lectures provide some of the methods you can use. So, this creative project brings realism to how you will use machine learning in the real world.  </p>\n",
    "\n",
    "The task you will work on is classifying texts to human emotions. Through words, humans express feelings, articulate thoughts, and communicate our deepest needs and desires. Language helps us interpret the nuances of joy, sadness, anger, and love, allowing us to connect with others on a deeper level. Are you able to train an ML model that recognizes the human emotions expressed in a piece of text? <b>Please read the project description PDF file carefully and follow the instructions there. Also make sure you write your code and answers to all the questions in this Jupyter Notebook </b> </p>\n",
    "<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 0: Basics</h2><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>0.1 Import:</h3><p>\n",
    "Please import necessary packages to use. Note that learning and using packages are recommended but not required for this project. Some official tutorial for suggested packacges includes:\n",
    "    \n",
    "https://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "    \n",
    "https://pytorch.org/tutorials/\n",
    "    \n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>0.2 Accuracy and Mean Squared Error:</h3><p>\n",
    "To measure your performance in the Kaggle Competition, we are using accuracy. As a recap, accuracy is the percent of labels you predict correctly. To measure this, you can use library functions from sklearn. A simple example is shown below. \n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [3, 2, 1, 0, 1, 2, 3]\n",
    "y_true = [0, 1, 2, 3, 1, 2, 3]\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 1: Basic</h2><p>\n",
    "Note that your code should be commented well and in part 1.4 you can refer to your comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1 Load and preprocess the dataset:</h3><p>\n",
    "We provide how to load the data on Kaggle's Notebook.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"/kaggle/input/cs-3780-5780-how-do-you-feel/train.csv\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train_text = train[\"text\"]\n",
    "train_label = train[\"label\"]\n",
    "\n",
    "# test = pd.read_csv(\"/kaggle/input/cs-3780-5780-how-do-you-feel/test.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test_id = test[\"id\"]\n",
    "test_text = test[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first take a look at the data we're given to decide how to put it\n",
    "into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i interact with on a daily basis either in rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger than fiction. Can't even begin to com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here with the aftermath feeling so damn ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great job! Hats off to you.</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i hate you threads posted by people just whini...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>im feeling so shy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Honestly if they were so worried about the tub...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Don't wear out our [NAME]. We need him if this...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Happy new year!</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>I got 4 wheel drive bro!</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     i interact with on a daily basis either in rea...      1\n",
       "1     Stranger than fiction. Can't even begin to com...      1\n",
       "2     i sit here with the aftermath feeling so damn ...      1\n",
       "3                           Great job! Hats off to you.     25\n",
       "4     i hate you threads posted by people just whini...      9\n",
       "...                                                 ...    ...\n",
       "9995                                  im feeling so shy      4\n",
       "9996  Honestly if they were so worried about the tub...     20\n",
       "9997  Don't wear out our [NAME]. We need him if this...     10\n",
       "9998                                    Happy new year!     19\n",
       "9999                           I got 4 wheel drive bro!     12\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure you comment your code clearly and you may refer to these comments in the part 1.4\n",
    "\n",
    "# Change all letters into lowercase\n",
    "# def preprocess_words(text):\n",
    "#   text = text.lower()\n",
    "#   text = re.sub(\"[^\\w\\s]\", \" \", text)\n",
    "#   text = text.split()\n",
    "#   return text\n",
    "\n",
    "# print(preprocess_words(\"Hello user123 245 doggies!...!hsdikj\"))\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing as our inputs are sentences and we want to predict labels,\n",
    "it makes sense to use a \"bag of words\" representation to\n",
    "represent the data. Each sentence will be represented by a\n",
    "vector that has a length of the total number of words in\n",
    "the vocabulary. Each vector's entry is 1 if the word is\n",
    "in the sentence, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X1 = vectorizer.fit_transform(train_text.to_list())\n",
    "X1 = X1.toarray()\n",
    "# print(vectorizer.get_feature_names_out())\n",
    "# print(X1)\n",
    "\n",
    "test_word_counts = vectorizer.transform(test_text.to_list())\n",
    "test_word_counts = test_word_counts.toarray()\n",
    "# print(test_word_counts.shape)\n",
    "# print(test_word_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2 Use At Least Two Training Algorithms from class:</h3><p>\n",
    "You need to use at least two training algorithms from class. You can use your code from previous projects or any packages you imported in part 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Naive Bayes</h5>\n",
    "\n",
    "We first try Naive Bayes model for classifying the words as\n",
    "it is a reasonable assumption to make that the words\n",
    "are independent of the label and it directly\n",
    "estimates probabilities for each word being in a class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you comment your code clearly and you may refer to these comments in the part 1.4\n",
    "# Naive Bayes\n",
    "\n",
    "def naivebayesPY(x,y):\n",
    "    \"\"\"\n",
    "    function [pos,neg] = naivebayesPY(x,y);\n",
    "\n",
    "    Computation of P(Y)\n",
    "    Input:\n",
    "        x : n input vectors of d dimensions (n,d)\n",
    "        y : n labels (one of 0 to 27) (n,)\n",
    "\n",
    "    Output:\n",
    "    probs: [prob p(y=0), ..., prob p(y=27)\n",
    "    \"\"\"\n",
    "    \n",
    "    n = float(len(y))\n",
    "    probs = []\n",
    "    for i in range(28):\n",
    "        probs.append(np.count_nonzero(y == i) / n)\n",
    "    return probs\n",
    "\n",
    "# probs = naivebayesPY(X1,train_label)\n",
    "# print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def naivebayesPXY_mle(x,y):\n",
    "#     \"\"\"\n",
    "#     function [posprob,negprob] = naivebayesPXY(x,y);\n",
    "    \n",
    "#     Computation of P(X|Y) -- Maximum Likelihood Estimate\n",
    "#     Input:\n",
    "#         x : n input vectors of d dimensions (n,d)\n",
    "#         y : n labels (-1 or +1) (n,)\n",
    "    \n",
    "#     Output:\n",
    "#     labelprobs: list of probability vectors of p(x|y=c) for c = 0..27\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # MLE = num of times letter x occurs in examples of class y / num of training examples in class y\n",
    "        \n",
    "#     # indices of positive and negative examples\n",
    "#     labelprobs = []\n",
    "#     for i in range(28):\n",
    "#         indices = np.argwhere(y == i).flatten()\n",
    "#         mat = x[indices]\n",
    "#         word_num = np.sum(mat, axis = 0)\n",
    "#         my = np.sum(mat)\n",
    "#         prob = word_num / my\n",
    "#         labelprobs.append(prob)\n",
    "    \n",
    "#     return labelprobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply smoothing to avoid 0 probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayesPXY_smoothing(x,y):\n",
    "    \"\"\"\n",
    "    function [posprob,negprob] = naivebayesPXY(x,y);\n",
    "    \n",
    "    Computation of P(X|Y) -- Smoothing with Laplace estimate\n",
    "    Input:\n",
    "        x : n input vectors of d dimensions (n,d)\n",
    "        y : n labels (-1 or +1) (n,)\n",
    "    \n",
    "    Output:\n",
    "    posprob: probability vector of p(x|y=1) (d,)\n",
    "    negprob: probability vector of p(x|y=-1) (d,)\n",
    "    \"\"\"\n",
    "\n",
    "    labelprobs = []\n",
    "    for i in range(28):\n",
    "        indices = np.argwhere(y == i).flatten()\n",
    "        mat = x[indices]\n",
    "        my = np.sum(mat)\n",
    "        counts = np.sum(mat, axis = 0)\n",
    "        sz = x.shape[1]\n",
    "        prob = (counts + 1) / (my + sz)\n",
    "        labelprobs.append(prob)\n",
    "    \n",
    "    return labelprobs\n",
    "\n",
    "\n",
    "# labelprobs_smooth = naivebayesPXY_smoothing(X1,train_label)\n",
    "# print(labelprobs_smooth[0])\n",
    "# print(np.log(labelprobs_smooth[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayes(x,y,xtest,naivebayesPXY):\n",
    "    \"\"\"\n",
    "    function logratio = naivebayes(x,y);\n",
    "    \n",
    "    Computation of log P(Y|X=x1) using Bayes Rule\n",
    "    Input:\n",
    "    x : n input vectors of d dimensions (n,d)\n",
    "    y : n labels (-1 or +1) (n,)\n",
    "    xtest: input vector of d dimensions (d,)\n",
    "    naivebayesPXY: input function for getting conditional probabilities (naivebayesPXY_smoothing)\n",
    "    \n",
    "    Output:\n",
    "    logratio: log (P(Y = 1|X=xtest)/P(Y=-1|X=xtest))\n",
    "    \"\"\"\n",
    "\n",
    "    labels_Y = naivebayesPY(x, y)   \n",
    "    labelprobs = naivebayesPXY(x, y)\n",
    "    \n",
    "    # summation of (num occurrences of word) * log(probability of letter)\n",
    "    pxy_lst = []\n",
    "    for i in range(28):\n",
    "      # print(\"here: \", labelprobs[i])\n",
    "      px_y = np.sum(np.multiply(xtest, np.log(labelprobs[i])))\n",
    "      pxy_lst.append(px_y)\n",
    "      # print(px_y)\n",
    "\n",
    "    logratios = []\n",
    "    for i in range(28):\n",
    "      numerator = np.log(labels_Y[i]) + pxy_lst[i]\n",
    "      denominator = 0\n",
    "      for j in range(28):\n",
    "         if i != j:\n",
    "           denominator = denominator + np.log(labels_Y[j]) + pxy_lst[j]  \n",
    "      logratios.append(numerator - denominator)\n",
    "    \n",
    "    return logratios\n",
    "\n",
    "# p_sm = naivebayes(X1, train_label, X1[0,:], naivebayesPXY_smoothing)\n",
    "# print(p_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayesCL(x,y,naivebayesPXY):\n",
    "    \"\"\"\n",
    "    function [w,b]=naivebayesCL(x,y);\n",
    "    Implementation of a Naive Bayes classifier\n",
    "    Input:\n",
    "    x : n input vectors of d dimensions (n,d)\n",
    "    y : n labels (-1 or +1) (n,)\n",
    "    naivebayesPXY: input function for getting conditional probabilities (naivebayesPXY_smoothing OR naivebayesPXY_mle)\n",
    "\n",
    "    Output:\n",
    "    w : weight vector of d dimensions (d,)\n",
    "    b : bias (scalar)\n",
    "    \"\"\"\n",
    "    \n",
    "    n, d = x.shape\n",
    "    \n",
    "    # bias\n",
    "    probs_Y = naivebayesPY(x, y)\n",
    "    bs = []\n",
    "    for i in range(28):\n",
    "        numer = probs_Y[i]\n",
    "        denom = 1 - probs_Y[i]\n",
    "        b = np.log(numer / denom)\n",
    "        bs.append(b)\n",
    "    \n",
    "    # weight (vector of d dimensions)\n",
    "    pxy_probs = naivebayesPXY(x, y)\n",
    "    ws = []\n",
    "    for i in range(28):\n",
    "        numerator = pxy_probs[i]\n",
    "        denominator = 0\n",
    "        for j in range(28):\n",
    "           if i != j:\n",
    "             denominator = denominator + pxy_probs[j]  \n",
    "        w = np.log(numerator / denominator)\n",
    "        ws.append(w)\n",
    "        \n",
    "    return ws, bs\n",
    "\n",
    "\n",
    "# weights_sm,biases_sm = naivebayesCL(X1,train_label, naivebayesPXY_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyLinear(x,ws,bs):\n",
    "    \"\"\"\n",
    "    function preds=classifyLinear(x,w,b);\n",
    "    \n",
    "    Make predictions with a linear classifier. Predictions should be signed. \n",
    "    Input:\n",
    "    x : n input vectors of d dimensions (n,d)\n",
    "    w : weight vector of d dimensions (d,)\n",
    "    b : bias\n",
    "    \n",
    "    Output:\n",
    "    preds: predictions\n",
    "    \"\"\"\n",
    "    ws = np.array(ws)\n",
    "    bs = np.array(bs)\n",
    "    # print(x.shape)\n",
    "    # print(ws.shape)\n",
    "    # print(bs.shape)\n",
    "    val = np.argmax(x @ ws.T + bs, axis=1)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Logistic Regression Model</h5>\n",
    "\n",
    "We then try a logistic regression model, as\n",
    "logistic regression models are designed for predicting outputs\n",
    "that are in categories. Instead of modeling based\n",
    "off of a binary output, we use multiclass logistic\n",
    "regression, as we have more than 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "\n",
    "# goal: use logistic regression to model y(labels) as a function of x(text)\n",
    "# input: vector with one entry for each word in sentence,\n",
    "# 1 if word is in sentence and 0 if not\n",
    "# output: label of text\n",
    "log_reg_model = LogisticRegression(random_state=42, max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3 Training, Validation and Model Selection:</h3><p>\n",
    "You need to split your data to a training set and validation set or performing a cross-validation for model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you comment your code clearly and you may refer to these comments in the part 1.4\n",
    "\n",
    "# split data into test, train, validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X1, train_label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first trained the Naive Bayes model on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Naive Bayes model on splits\n",
    "p_sm = naivebayes(X_train, y_train, X_train[0,:], naivebayesPXY_smoothing)\n",
    "weights_sm, biases_sm = naivebayesCL(X_train, y_train, naivebayesPXY_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error (Smoothing with Laplace estimate): 38.56%\n",
      "Training accuracy score: 61.00%\n",
      "Validation error (Smoothing with Laplace estimate): 50.97%\n",
      "Validation accuracy score: 49.00%\n"
     ]
    }
   ],
   "source": [
    "# calculate training and test error\n",
    "naive_bayes_train_preds = classifyLinear(X_train, weights_sm, biases_sm)\n",
    "naive_bayes_val_preds = classifyLinear(X_val, weights_sm, biases_sm)\n",
    "\n",
    "print('Training error (Smoothing with Laplace estimate): %.2f%%' % (100 *(naive_bayes_train_preds != y_train).mean()))\n",
    "print(f\"Training accuracy score: {100 * round(accuracy_score(naive_bayes_train_preds, y_train),2):.2f}%\")\n",
    "\n",
    "print('Validation error (Smoothing with Laplace estimate): %.2f%%' % (100 *(naive_bayes_val_preds != y_val).mean()))\n",
    "print(f\"Validation accuracy score: {100 * round(accuracy_score(naive_bayes_val_preds, y_val),2):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we trained the Logistic Regression model on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=10000, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train logistic regression model on splits\n",
    "log_reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error with logistic regression: 3.01%\n",
      "Accuracy score: 97.00%\n",
      "Validation error with logistic regression: 29.67%\n",
      "Validation accuracy score: 70.00%\n"
     ]
    }
   ],
   "source": [
    "# make test predictions and calculate accuracy\n",
    "log_reg_train_preds = log_reg_model.predict(X_train)\n",
    "log_reg_val_preds = log_reg_model.predict(X_val)\n",
    "\n",
    "print(f\"Training error with logistic regression: \\\n",
    "{100 * (np.round(log_reg_train_preds) != y_train).mean():.2f}%\")\n",
    "print(f\"Accuracy score: \\\n",
    "{100 * round(accuracy_score(log_reg_train_preds, y_train),2):.2f}%\")\n",
    "\n",
    "print(f\"Validation error with logistic regression: \\\n",
    "{100 * (np.round(log_reg_val_preds) != y_val).mean():.2f}%\")\n",
    "print(f\"Validation accuracy score: \\\n",
    "{100 * round(accuracy_score(log_reg_val_preds, y_val), 2):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "# X_test_nb = vectorizer.transform(test_text.to_list()) \n",
    "\n",
    "# p_sm = naivebayes(X1, train_label, test_text, naivebayesPXY_smoothing)\n",
    "# weights_test_nb,biases_test_nb = naivebayesCL(train_text,train_label, naivebayesPXY_smoothing)\n",
    "# classifyLinear(test_text, weights_test_nb, biases_test_nb)\n",
    "\n",
    "# classifyLinear(X_test_nb, weights_sm,biases_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.4 Explanation in Words:</h3><p>\n",
    "    You need to answer the following questions in the markdown cell after this cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4.1 How did you formulate the learning problem?\n",
    "\n",
    "The problem is that we have text in sentences that we aim\n",
    "to classify into a finite amount of groups. In other words,\n",
    "our input is text, and we want to output a number representing\n",
    "a class for that text. We decided to use the \"bag of words\"\n",
    "representation to represent the text, where each piece of\n",
    "text is represented by a vector.\n",
    "\n",
    "1.4.2 Which two learning methods from class did you choose and why did you made the choices?\n",
    "\n",
    "We chose a **Naive Bayes classifier** and a\n",
    "**Multiclass Logistic Regression classifier**.\n",
    "Naive Bayes was chosen becuase the model directly\n",
    "estimates probabilities for each word being in a class.\n",
    "Multiclass Logistic Regression was chosen because this\n",
    "regression was designed to make predictions on an\n",
    "output that falls into multiple categories.\n",
    "\n",
    "1.4.3 How did you do the model selection?\n",
    "\n",
    "We wanted to avoid having 0 valued probabilities,\n",
    "so we used Laplace Smoothing for our Naive Bayes model.\n",
    "We used a multiclass logistic regression because we have\n",
    "28 emotions that we want to predict.\n",
    "\n",
    "1.4.4 Does the test performance reach the first baseline \"Tiny Piney\"? (Please include a screenshot of Kaggle Submission)\n",
    "\n",
    "The test performance does reach the first baseline.\n",
    "**INSERT SCREENSHOT HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 2: Be creative!</h2><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.1 Open-ended Code:</h3><p>\n",
    "You may follow the steps in part 1 again but making innovative changes like using new training algorithms, etc. Make sure you explain everything clearly in part 2.2. Note that beating \"Zero Hero\" is only a small portion of this part. Any creative ideas will receive most points as long as they are reasonable and clearly explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you comment your code clearly and you may refer to these comments in the part 2.2\n",
    "# Transformer\n",
    "# Tutorial from: https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
    "# helpful for determining d_model: https://discuss.pytorch.org/t/embed-dim-must-be-divisible-by-num-heads/54394/3\n",
    "# print(X1[0].shape)\n",
    "# d_model = 512\n",
    "# n_head = 16\n",
    "# transformer_model = nn.Transformer(d_model=d_model, nhead=n_head, num_encoder_layers=12)\n",
    "# print(transformer_model.d_model)\n",
    "\n",
    "# truncate each sentence to use first `transformer_model.d_model` words\n",
    "# src = torch.tensor(X1[:, :d_model])\n",
    "# tgt = torch.tensor(X1[:, :d_model])\n",
    "# print(src.shape)\n",
    "# print(tgt.shape)\n",
    "# src = torch.rand((10, 32, transformer_model.d_model))\n",
    "# tgt = torch.rand((20, 32, transformer_model.d_model))\n",
    "# out = transformer_model(src, tgt)\n",
    "# out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Linear Regression Model</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression model\n",
    "\n",
    "# goal: use linear regression to model y(labels) as a function of x(text)\n",
    "# input: vector with one entry for each word in sentence,\n",
    "# 1 if word is in sentence and 0 if not\n",
    "# output: label of text\n",
    "# model2_X = train[['text']]\n",
    "# print(X1.shape)\n",
    "# print(train_label.shape)\n",
    "# model = LinearRegression().fit(X1, train_label)\n",
    "# print(model.coef_)\n",
    "# print(model.coef_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test predictions and calculate accuracy\n",
    "# linreg_train_preds = model.predict(X1)\n",
    "# print(linreg_train_preds[:10])\n",
    "# print(np.round(linreg_train_preds)[:10])\n",
    "# linreg_test_preds = model.predict(test_word_counts)\n",
    "\n",
    "# print(test[['text']].shape)\n",
    "# print(f\"Training error with linear regression: {100 * (np.round(linreg_train_preds) != train_label).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.2 Explanation in Words:</h3><p>\n",
    "You need to answer the following questions in a markdown cell after this cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1 How much did you manage to improve performance on the test set? Did you beat \"Zero Hero\" in Kaggle? (Please include a screenshot of Kaggle Submission)\n",
    "\n",
    "2.2.2 Please explain in detail how you achieved this and what you did specifically and why you tried this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 3: Kaggle Submission</h2><p>\n",
    "You need to generate a prediction CSV using the following cell from your trained model and submit the direct output of your code to Kaggle. The results should be presented in two columns in csv format: the first column is the data id (0-14999) and the second column includes the predictions for the test set. The first column must be named id and the second column must be named label (otherwise your submission will fail). A sample predication file can be downloaded from Kaggle for each problem. \n",
    "We provide how to save a csv file if you are running Notebook on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = range(len(test_id))\n",
    "prediction = prediction = range(15000)\n",
    "submission = pd.DataFrame({'id': id, 'label': prediction})\n",
    "# submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "# submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>14995</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>14996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>14997</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>14998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>14999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "0          0     27\n",
       "1          1     16\n",
       "2          2     21\n",
       "3          3     21\n",
       "4          4     21\n",
       "...      ...    ...\n",
       "14995  14995      9\n",
       "14996  14996      9\n",
       "14997  14997     12\n",
       "14998  14998      1\n",
       "14999  14999      1\n",
       "\n",
       "[15000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log Reg predictions\n",
    "id = range(len(test_id))\n",
    "# submission_preds = log_reg_model.predict(test_word_counts[:, :X_train.shape[1]])\n",
    "submission_preds = log_reg_model.predict(test_word_counts)\n",
    "preds_df = pd.DataFrame({'id': id, 'label': submission_preds})\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 4: Resources and Literature Used</h2><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please cite the papers and open resources you used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
